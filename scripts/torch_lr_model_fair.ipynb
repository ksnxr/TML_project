{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbc3338",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://github.com/jf20541/LogisticRegressionPyTorch/blob/main/src/pytorchmodel.py\n",
    "2. https://pytorch.org/tutorials/beginner/basics/\n",
    "3. https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch\n",
    "4. https://gist.github.com/tuelwer/0b52817e9b6251d940fd8e2921ec5e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fef186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x122055f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random_state = 1\n",
    "torch.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cda852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit Amount</th>\n",
       "      <th>Installment rate</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of credits</th>\n",
       "      <th>Maintenance</th>\n",
       "      <th>Target</th>\n",
       "      <th>Account Status_&lt;0</th>\n",
       "      <th>Account Status_&lt;200</th>\n",
       "      <th>...</th>\n",
       "      <th>Housing_own</th>\n",
       "      <th>Housing_rent</th>\n",
       "      <th>Job_management/ highly qualified employee</th>\n",
       "      <th>Job_skilled employee / official</th>\n",
       "      <th>Job_unemployed/ unskilled  - non-resident</th>\n",
       "      <th>Job_unskilled - resident</th>\n",
       "      <th>Telephone_none</th>\n",
       "      <th>Telephone_yes</th>\n",
       "      <th>Foreign_no</th>\n",
       "      <th>Foreign_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>5951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration  Credit Amount  Installment rate  Residence  Age  \\\n",
       "0         6           1169                 4          4   67   \n",
       "1        48           5951                 2          2   22   \n",
       "2        12           2096                 2          3   49   \n",
       "3        42           7882                 2          4   45   \n",
       "4        24           4870                 3          4   53   \n",
       "\n",
       "   Number of credits  Maintenance  Target  Account Status_<0  \\\n",
       "0                  2            1       1                  1   \n",
       "1                  1            1       0                  0   \n",
       "2                  1            2       1                  0   \n",
       "3                  1            2       1                  1   \n",
       "4                  2            2       0                  1   \n",
       "\n",
       "   Account Status_<200  ...  Housing_own  Housing_rent  \\\n",
       "0                    0  ...            1             0   \n",
       "1                    1  ...            1             0   \n",
       "2                    0  ...            1             0   \n",
       "3                    0  ...            0             0   \n",
       "4                    0  ...            0             0   \n",
       "\n",
       "   Job_management/ highly qualified employee  Job_skilled employee / official  \\\n",
       "0                                          0                                1   \n",
       "1                                          0                                1   \n",
       "2                                          0                                0   \n",
       "3                                          0                                1   \n",
       "4                                          0                                1   \n",
       "\n",
       "   Job_unemployed/ unskilled  - non-resident  Job_unskilled - resident  \\\n",
       "0                                          0                         0   \n",
       "1                                          0                         0   \n",
       "2                                          0                         1   \n",
       "3                                          0                         0   \n",
       "4                                          0                         0   \n",
       "\n",
       "   Telephone_none  Telephone_yes  Foreign_no  Foreign_yes  \n",
       "0               0              1           0            1  \n",
       "1               1              0           0            1  \n",
       "2               1              0           0            1  \n",
       "3               1              0           0            1  \n",
       "4               1              0           0            1  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cleaned.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb73d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 36, 37, 38, 39, 59, 60],\n",
       " ['Age',\n",
       "  'Sex_female divorced/separated/married',\n",
       "  'Sex_male divorced/separated',\n",
       "  'Sex_male married/widowed',\n",
       "  'Sex_male single',\n",
       "  'Foreign_no',\n",
       "  'Foreign_yes'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitive_indexes = []\n",
    "sensitive_columns = []\n",
    "\n",
    "for index, column in enumerate(df.loc[:, df.columns != 'Target'].columns):\n",
    "    if column.startswith(\"Sex\") or column.startswith(\"Age\") or column.startswith(\"Foreign\"):\n",
    "        sensitive_indexes.append(index)\n",
    "        sensitive_columns.append(column)\n",
    "        \n",
    "sensitive_indexes, sensitive_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df1accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_regularizer(data, preds):\n",
    "#     assert data.shape[0] == preds.shape[0]\n",
    "\n",
    "    combined = [\"\" for _ in range(data.shape[0])]\n",
    "\n",
    "    for i in sensitive_indexes:\n",
    "        for j in range(data.shape[0]):\n",
    "            combined[j] = combined[j] + \"_\" + str(data[j, i].item())\n",
    "\n",
    "    counts = dict()\n",
    "    for index, entry in enumerate(combined):\n",
    "        if entry not in counts:\n",
    "            counts[entry] = [index]\n",
    "        else:\n",
    "            indexes = counts[entry]\n",
    "            indexes.append(index)\n",
    "            counts[entry] = indexes\n",
    "        \n",
    "    pr_y1_si = [0 for _ in range(data.shape[0])]\n",
    "    preds_sum_dict = dict()\n",
    "\n",
    "    for idx, entry in enumerate(combined):\n",
    "        indexes = counts[entry]\n",
    "\n",
    "        if entry in preds_sum_dict:\n",
    "            preds_sum = preds_sum_dict[entry]\n",
    "        else:\n",
    "            preds_sum = 0\n",
    "            for index in indexes:\n",
    "                preds_sum += preds[index].detach().item()\n",
    "            preds_sum_dict[entry] = preds_sum\n",
    "            \n",
    "        pr_y1_si[idx] = preds_sum / len(indexes)\n",
    "\n",
    "    pr_y1_si = torch.tensor(pr_y1_si)\n",
    "    pr_y0_si = 1 - pr_y1_si\n",
    "    \n",
    "    pr_y1 = torch.sum(preds) / data.shape[0]\n",
    "    pr_y0 = 1 - pr_y1\n",
    "    \n",
    "    pr_0 = torch.nan_to_num(torch.clamp(torch.log(pr_y0_si / pr_y0), min=-5., max=5.), 0.)\n",
    "    pr_1 = torch.nan_to_num(torch.clamp(torch.log(pr_y1_si / pr_y1), min=-5., max=5.), 0.)\n",
    "\n",
    "    return torch.sum((1 - preds) * pr_0 + preds * pr_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b370048",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.tensor(df.loc[:, df.columns != 'Target'].values)\n",
    "ys = torch.tensor(df['Target'].values)\n",
    "ys = ys.reshape(ys.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efee841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3058c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "l2_lambda = 0.01\n",
    "fairness_lambda = 0\n",
    "\n",
    "\n",
    "def test_loop(Xs, ys, model, threshold=0.72):\n",
    "    \"\"\"\n",
    "    If the model fails to find a reasonable solution, return True\n",
    "    \"\"\"\n",
    "    size = Xs.shape[0]\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(Xs.float())\n",
    "        test_loss += loss_fn(pred, ys.float()).item()\n",
    "        \n",
    "        # l2 regularization\n",
    "        l2_reg = torch.tensor(0.)\n",
    "        for w in model.parameters():\n",
    "            l2_reg += w.norm(2)\n",
    "        test_loss += l2_lambda * l2_reg\n",
    "    \n",
    "        correct += ((pred > 0.5).float() == ys).type(torch.float).sum().item()\n",
    "        \n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return correct <= threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "888d7dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m test_loop(Xs, ys, model):\n\u001b[1;32m     34\u001b[0m     model \u001b[38;5;241m=\u001b[39m run_training()\n",
      "Cell \u001b[0;32mIn [8], line 28\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 28\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/optim/lbfgs.py:425\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 425\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    428\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/optim/lbfgs.py:49\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     47\u001b[0m g \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# evaluate objective and gradient using initial step\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     51\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/optim/lbfgs.py:423\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/optim/lbfgs.py:277\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m--> 277\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    278\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [8], line 10\u001b[0m, in \u001b[0;36mrun_training.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m      9\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(Xs\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# l2 regularization\u001b[39;00m\n\u001b[1;32m     13\u001b[0m l2_reg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/nn/modules/loss.py:613\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.9/site-packages/torch/nn/functional.py:3083\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3080\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3081\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "def run_training():\n",
    "    model = LogisticRegression(Xs.shape[1], 1)\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1, line_search_fn='strong_wolfe')\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(Xs.float())\n",
    "        loss = loss_fn(pred, ys.float())\n",
    "\n",
    "        # l2 regularization\n",
    "        l2_reg = torch.tensor(0.)\n",
    "        for w in model.parameters():\n",
    "            l2_reg += w.norm(2)\n",
    "        loss += l2_lambda * l2_reg\n",
    "        \n",
    "        # fairness regularizer\n",
    "        fairness_regularization = get_fairness_regularizer(Xs.float(), pred)\n",
    "        loss += fairness_lambda * fairness_regularization\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    epochs = 20\n",
    "    for t in range(epochs):\n",
    "        optimizer.step(closure)\n",
    "        \n",
    "    return model\n",
    "    \n",
    "model = run_training()\n",
    "while test_loop(Xs, ys, model):\n",
    "    model = run_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds = np.zeros(df.shape[0], dtype=int)\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "# for train_index, test_index in kf.split(df):\n",
    "#     X_train, y_train = Xs.iloc[train_index], ys.iloc[train_index]\n",
    "#     X_test, y_test = Xs.iloc[test_index], ys.iloc[test_index]\n",
    "    \n",
    "#     X_train = torch.tensor(X_train.values)\n",
    "#     y_train = torch.tensor(y_train.values)\n",
    "#     y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "#     X_test = torch.tensor(X_test.values)\n",
    "    \n",
    "#     model = run_training(X_train, y_train)\n",
    "#     while test(X_train, y_train, model):\n",
    "#         model = run_training(X_train, y_train)\n",
    "    \n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         all_preds[test_index] = model(X_test.float()).numpy().squeeze() > 0.5\n",
    "# #     print(accuracy_score(y_test, preds))\n",
    "\n",
    "# accuracy_score(ys, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_df = pd.read_csv('../data/orig.csv', index_col=0)\n",
    "# orig_df.rename(columns={\"Target\": \"label_value\"}, inplace=True)\n",
    "# orig_df['score'] = all_preds\n",
    "# orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52800c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_df.to_csv('../data/processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
